{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_path1 = '/root/shuju/xunlianji2.csv'\n",
    "file_path2 = '/root/shuju/ceshiji.csv'\n",
    "data = np.genfromtxt(file_path1, delimiter=',', skip_header=1)\n",
    "data_test = np.genfromtxt(file_path2, delimiter=',', skip_header=1)\n",
    "np.save('/root/shuju/fangan3data2mev.npy', data)\n",
    "np.save('/root/shuju/2015-10-12.npy', data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "input_file_path1 = '/root/shuju/fangan3data2mev.npy'  \n",
    "input_file_path2 = '/root/shuju/2015-10-12.npy'\n",
    "\n",
    "data1 = np.load(input_file_path1)\n",
    "datax = data1[:,1:50]                      \n",
    "datay = np.reshape(data1[:, 50],(-1,1))    \n",
    "print(datax.shape)\n",
    "print(datay.shape)\n",
    "\n",
    "data3 = np.load(input_file_path2)\n",
    "datax_test = data3[:,1:50]                     \n",
    "datay_test = np.reshape(data3[:, 50],(-1,1))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax = mm.fit_transform(datax)\n",
    "datay = mm.fit_transform(datay)\n",
    "datax_test = mm.fit_transform(datax_test)\n",
    "datay_test = mm.fit_transform(datay_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datax)\n",
    "print(datay)\n",
    "\n",
    "print(datax_test)\n",
    "print(datay_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(datax)\n",
    "y_data = np.array(datay)\n",
    "\n",
    "x_test = np.array(datax_test)\n",
    "y_test = np.array(datay_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def pe(y_true, y_pred):\n",
    "    return 1 - (K.sum(K.square(y_pred - y_true)) / K.sum(K.square(y_true - K.mean(y_true))))\n",
    "\n",
    "def cc(y_true, y_pred):\n",
    "    mean_true = K.mean(y_true)\n",
    "    mean_pred = K.mean(y_pred)\n",
    "    covar = K.mean((y_true - mean_true) * (y_pred - mean_pred))\n",
    "    std_true = K.std(y_true)\n",
    "    std_pred = K.std(y_pred)\n",
    "    return covar / (std_true * std_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    sigmoid_coefficient = (1 + (69.92719340161796 / (1 + tf.exp(-5.53710329830428 * (y_true - 3.504586735373479)))))\n",
    "    loss = K.mean(K.square(y_pred - y_true) * sigmoid_coefficient)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_1 = 42\n",
    "activation_1 = 'relu'\n",
    "reg_param_1 = 9.755667800692107e-05\n",
    "regularizer_1 = tf.keras.regularizers.l1(reg_param_1)\n",
    "\n",
    "model.add(layers.Dense(num_hidden_1, kernel_initializer='he_normal', activation=activation_1, kernel_regularizer=regularizer_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import he_normal\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def pred_model():\n",
    "    model = tf.keras.Sequential()  \n",
    "    model.add(layers.Dense(49, kernel_initializer='he_normal', activation='relu', input_shape=(49,)))\n",
    "    num_hidden_1 = 61\n",
    "    activation_1 = 'relu'\n",
    "    reg_param_1 = 0.005\n",
    "    regularizer_1 = tf.keras.regularizers.l2(reg_param_1)\n",
    "    model.add(layers.Dense(num_hidden_1, kernel_initializer='he_normal', activation=activation_1, kernel_regularizer=regularizer_1))\n",
    "    num_hidden_2 = 56\n",
    "    activation_2 = 'relu'\n",
    "    reg_param_2 = 0.001\n",
    "    regularizer_2 = tf.keras.regularizers.l1(reg_param_2)    \n",
    "    model.add(layers.Dense(num_hidden_2, kernel_initializer='he_normal', activation=activation_2, kernel_regularizer=regularizer_2))\n",
    "    num_hidden_3 = 58\n",
    "    activation_3 = 'sigmoid'\n",
    "    reg_param_3 = 0.001\n",
    "    regularizer_3 = tf.keras.regularizers.l2(reg_param_3)     \n",
    "    model.add(layers.Dense(num_hidden_3, kernel_initializer='he_normal', activation=activation_3, kernel_regularizer=regularizer_3))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pred_model()  \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',    \n",
    "                             factor=0.7,            \n",
    "                             patience=20,            \n",
    "                             mode='auto',          \n",
    "                             verbose=1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                               patience=20, \n",
    "                               verbose=1, \n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "group_size = 288\n",
    "num_groups = len(x_data) // group_size\n",
    "num_folds = 12\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "all_train_losses = []\n",
    "all_val_losses = []\n",
    "k_fold_pe_values = []\n",
    "weights_list = []\n",
    "with open('/root/shuju/training_process.txt', 'w') as file:\n",
    "    for fold, (train_groups, val_groups) in enumerate(kf.split(range(num_groups))):\n",
    "        file.write(f\"在第 {fold + 1}/{num_folds} 折上进行训练\\n\")\n",
    "        train_indices = [idx for group_idx in train_groups for idx in range(group_idx * group_size, (group_idx + 1) * group_size)]\n",
    "        val_indices = [idx for group_idx in val_groups for idx in range(group_idx * group_size, (group_idx + 1) * group_size)]\n",
    "        x_train, y_train = x_data[train_indices], y_data[train_indices]\n",
    "        x_val, y_val = x_data[val_indices], y_data[val_indices]\n",
    "        model.compile(optimizer='adam', loss=custom_loss, metrics=[rmse, pe, cc])\n",
    "        checkpoint_filepath = f\"/root/shuju/fangan72mev_model_fold_{fold}.h5\"\n",
    "        model_checkpoint = ModelCheckpoint(checkpoint_filepath, \n",
    "                                            save_best_only=True, \n",
    "                                            save_weights_only=True, \n",
    "                                            monitor='val_loss', \n",
    "                                            mode='min',         \n",
    "                                            verbose=1)    \n",
    "        history = model.fit(x_train, \n",
    "                            y_train, \n",
    "                            epochs=87, \n",
    "                            batch_size=1200, \n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=1, \n",
    "                            shuffle=True, \n",
    "                            callbacks=[reduce_lr, model_checkpoint,early_stopping])\n",
    "\n",
    "        file.write(f\"训练历史：{history.history['loss']}\\n\")\n",
    "        file.write(f\"验证历史：{history.history['val_loss']}\\n\")\n",
    "        file.write(f\"验证 PE 值：{history.history['val_pe']}\\n\")\n",
    "        all_train_losses.append(history.history['loss'])\n",
    "        all_val_losses.append(history.history['val_loss'])\n",
    "        k_fold_pe_values.append(history.history['val_pe'])\n",
    "        weights = model.get_weights()\n",
    "        weights_list.append(weights)\n",
    "\n",
    "average_weights = np.mean(weights_list, axis=0)\n",
    "model.set_weights(average_weights)\n",
    "average_weights_filepath = \"/root/shuju/fangan72mev_average_weights.h5\"\n",
    "model.save_weights(average_weights_filepath)\n",
    "print(f\"平均权重已保存至 {average_weights_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "miniepoch = 20\n",
    "all_train_losses = [epoch_data[:miniepoch] for epoch_data in all_train_losses]\n",
    "all_val_losses = [epoch_data[:miniepoch] for epoch_data in all_val_losses]\n",
    "\n",
    "all_train_losses = np.array(all_train_losses)\n",
    "all_val_losses = np.array(all_val_losses)\n",
    "mean_train_loss = np.mean(np.array(all_train_losses), axis=0)\n",
    "mean_val_loss = np.mean(np.array(all_val_losses), axis=0)\n",
    "std_train_loss = np.std(np.array(all_train_losses), axis=0)\n",
    "std_val_loss = np.std(np.array(all_val_losses), axis=0)\n",
    "\n",
    "c = range(miniepoch)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(c, mean_train_loss, \"b-\", linestyle='solid', label=\"mean_train_loss\")\n",
    "ax.plot(c, mean_val_loss, \"r-\", linestyle='solid', label=\"mean_val_loss\")\n",
    "ax.fill_between(c, mean_train_loss - std_train_loss, mean_train_loss + std_train_loss, color='blue', alpha=0.3)\n",
    "ax.fill_between(c, mean_val_loss - std_val_loss, mean_val_loss + std_val_loss, color='red', alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('value')\n",
    "ax.set_title('2mev: Compare mean_train_loss and mean_val_loss with standard deviation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "k_fold_pe_values = [epoch_data[:miniepoch] for epoch_data in k_fold_pe_values]\n",
    "k_fold_pe_values = np.array(k_fold_pe_values)\n",
    "\n",
    "mean_pe_values = np.mean(k_fold_pe_values, axis=0)\n",
    "std_pe_values = np.std(k_fold_pe_values, axis=0)\n",
    "\n",
    "epochs = range(1, len(mean_pe_values) + 1)\n",
    "\n",
    "plt.plot(epochs, mean_pe_values, marker='o', linestyle='-', color='b', label='mean_PE')\n",
    "plt.fill_between(epochs, mean_pe_values - std_pe_values, mean_pe_values + std_pe_values, color='blue', alpha=0.3, label='std_dev_PE')\n",
    "\n",
    "plt.title('2mev: PE vs. Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/root/shuju/fangan72mev_average_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "y_pred_test = mm.inverse_transform(model.predict(datax_test))\n",
    "y_val_test = mm.inverse_transform(datay_test)\n",
    "\n",
    "data = {\n",
    "    '真实值': y_val_test.ravel(),\n",
    "    '预测值': y_pred_test.ravel()       \n",
    "    \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "output_file = '/root/shuju/fangan3bijiao2mev.csv'  \n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'预测值和真实值已保存到 {output_file}')\n",
    "\n",
    "print(\"预测值：\")\n",
    "print(y_pred_test)\n",
    "print(\"真实值：\")\n",
    "print(y_val_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file1 = '/root/shuju/ceshiji.csv'  \n",
    "df1 = pd.read_csv(input_file1)\n",
    "\n",
    "\n",
    "input_file2 = '/root/shuju/fangan3bijiao2mev.csv'  \n",
    "df2 = pd.read_csv(input_file2)\n",
    "\n",
    "column1 = df2.iloc[:, 0]\n",
    "column2 = df2.iloc[:, 1]\n",
    "\n",
    "df2['真实值'] = column1  \n",
    "df2['预测值'] = column2  \n",
    "\n",
    "column3 = df2.iloc[:, :]  \n",
    "merged_df = pd.concat([df1.iloc[:, 0], column3], axis=1)\n",
    "output_file = '/root/shuju/fangan3bijiao2mev.csv'  \n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'数据已整合到 {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.read_csv('/root/shuju/ceshiji.csv')\n",
    "dates_filtered = df_original[df_original['2mev_next'] >= 3.5]['Formatted Date']\n",
    "df_comparison = pd.read_csv('/root/shuju/fangan3bijiao2mev.csv')\n",
    "df_filtered = df_comparison[df_comparison['Formatted Date'].isin(dates_filtered)]\n",
    "df_filtered.to_csv('/root/shuju/filtered_data_based_on_date.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
