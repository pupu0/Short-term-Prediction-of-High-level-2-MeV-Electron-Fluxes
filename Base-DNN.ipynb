{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.io import readsav\n",
    "import keras.backend as b\n",
    "import pandas as pd\n",
    "import keras as K\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import joblib\n",
    "# from sklearn import cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from sklearn import preprocessing\n",
    "# from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8 \n",
    "config.gpu_options.allow_growth = True    \n",
    "sess = tf.compat.v1.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_path1 = '/shuju/全部数据的训练集.csv'\n",
    "file_path2 = '/shuju/全部数据的测试集.csv'\n",
    "\n",
    "data = np.genfromtxt(file_path1, delimiter=',', skip_header=1) \n",
    "data_test = np.genfromtxt(file_path2, delimiter=',', skip_header=1)\n",
    "\n",
    "np.save('/shuju/fangan3data2mev.npy', data)\n",
    "np.save('/shuju/2015-10-12.npy', data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "input_file_path1 = '/shuju/fangan3data2mev.npy'  \n",
    "input_file_path2 = '/shuju/2015-10-12.npy'\n",
    "data1 = np.load(input_file_path1)\n",
    "datax = data1[:,1:50]                     \n",
    "datay = np.reshape(data1[:, 50],(-1,1))   \n",
    "print(datax.shape)\n",
    "print(datay.shape)\n",
    "data3 = np.load(input_file_path2)\n",
    "datax_test = data3[:,1:50]                    \n",
    "datay_test = np.reshape(data3[:, 50],(-1,1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax = mm.fit_transform(datax)\n",
    "datay = mm.fit_transform(datay)\n",
    "datax_test = mm.fit_transform(datax_test)\n",
    "datay_test = mm.fit_transform(datay_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(datax)\n",
    "y_data = np.array(datay)\n",
    "\n",
    "x_test = np.array(datax_test)\n",
    "y_test = np.array(datay_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# 定义预测效率（PE）评估指标\n",
    "def pe(y_true, y_pred):\n",
    "    return 1 - (K.sum(K.square(y_pred - y_true)) / K.sum(K.square(y_true - K.mean(y_true))))\n",
    "\n",
    "# 定义相关系数（CC）评估指标\n",
    "def cc(y_true, y_pred):\n",
    "    mean_true = K.mean(y_true)\n",
    "    mean_pred = K.mean(y_pred)\n",
    "    covar = K.mean((y_true - mean_true) * (y_pred - mean_pred))\n",
    "    std_true = K.std(y_true)\n",
    "    std_pred = K.std(y_pred)\n",
    "    return covar / (std_true * std_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import he_normal\n",
    "\n",
    "def pred_model():\n",
    "    model = Sequential()  \n",
    "    model.add(Dense(49, kernel_initializer=he_normal(), activation='relu', input_shape=(49,)))\n",
    "    model.add(Dense(25, kernel_initializer=he_normal(), activation='relu'))\n",
    "    model.add(Dropout(0.2)) \n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "model = pred_model()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pred_model()  \n",
    "reduce_lr = ReduceLROnPlateau(monitor='pe',    \n",
    "                             factor=0.7,         \n",
    "                             patience=20,       \n",
    "                             mode='auto',      \n",
    "                             verbose=1)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = pred_model()  \n",
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                               patience=20, \n",
    "                               verbose=1, \n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "group_size = 288\n",
    "num_groups = len(x_data) // group_size\n",
    "\n",
    "num_folds = 12\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "all_train_losses = []\n",
    "all_val_losses = []\n",
    "k_fold_pe_values = []\n",
    "weights_list = []\n",
    "\n",
    "for fold, (train_groups, val_groups) in enumerate(kf.split(range(num_groups))):   \n",
    "    print(f\"在第 {fold + 1}/{num_folds} 折上进行训练\")\n",
    "    train_indices = [idx for group_idx in train_groups for idx in range(group_idx * group_size, (group_idx + 1) * group_size)]\n",
    "    val_indices = [idx for group_idx in val_groups for idx in range(group_idx * group_size, (group_idx + 1) * group_size)]\n",
    "    x_train, y_train = x_data[train_indices], y_data[train_indices]\n",
    "    x_val, y_val = x_data[val_indices], y_data[val_indices]\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=[rmse, pe, cc])\n",
    "    checkpoint_filepath = f\"/shuju/model/fangan32mev_model_fold_{fold}.h5\"\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_filepath, \n",
    "                                        save_best_only=True, \n",
    "                                        save_weights_only=True, \n",
    "                                        monitor='val_loss', \n",
    "                                        mode='min',          \n",
    "                                        verbose=1)    \n",
    "    history = model.fit(x_train, \n",
    "                        y_train, \n",
    "                        epochs=100, \n",
    "                        batch_size=500, \n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1, \n",
    "                        shuffle=False, \n",
    "                        callbacks=[reduce_lr, model_checkpoint])\n",
    "\n",
    "    all_train_losses.append(history.history['loss'])\n",
    "    all_val_losses.append(history.history['val_loss'])\n",
    "    k_fold_pe_values.append(history.history['val_pe'])\n",
    "\n",
    "    weights = model.get_weights()\n",
    "    weights_list.append(weights)\n",
    "\n",
    "average_weights = np.mean(weights_list, axis=0)\n",
    "model.set_weights(average_weights)\n",
    "average_weights_filepath = \"/shuju/fangan32mev_average_weights.h5\"\n",
    "model.save_weights(average_weights_filepath)\n",
    "print(f\"平均权重已保存至 {average_weights_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "miniepoch = 20\n",
    "all_train_losses = [epoch_data[:miniepoch] for epoch_data in all_train_losses]\n",
    "all_val_losses = [epoch_data[:miniepoch] for epoch_data in all_val_losses]\n",
    "\n",
    "all_train_losses = np.array(all_train_losses)\n",
    "all_val_losses = np.array(all_val_losses)\n",
    "\n",
    "mean_train_loss = np.mean(np.array(all_train_losses), axis=0)\n",
    "mean_val_loss = np.mean(np.array(all_val_losses), axis=0)\n",
    "std_train_loss = np.std(np.array(all_train_losses), axis=0)\n",
    "std_val_loss = np.std(np.array(all_val_losses), axis=0)\n",
    "\n",
    "\n",
    "c = range(miniepoch)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(c, mean_train_loss, \"b-\", linestyle='solid', label=\"mean_train_loss\")\n",
    "ax.plot(c, mean_val_loss, \"r-\", linestyle='solid', label=\"mean_val_loss\")\n",
    "\n",
    "ax.fill_between(c, mean_train_loss - std_train_loss, mean_train_loss + std_train_loss, color='blue', alpha=0.3)\n",
    "ax.fill_between(c, mean_val_loss - std_val_loss, mean_val_loss + std_val_loss, color='red', alpha=0.3)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('value')\n",
    "ax.set_title('2mev: Compare mean_train_loss and mean_val_loss with standard deviation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "k_fold_pe_values = [epoch_data[:miniepoch] for epoch_data in k_fold_pe_values]\n",
    "k_fold_pe_values = np.array(k_fold_pe_values)\n",
    "\n",
    "# 计算平均值和标准差\n",
    "mean_pe_values = np.mean(k_fold_pe_values, axis=0)\n",
    "std_pe_values = np.std(k_fold_pe_values, axis=0)\n",
    "\n",
    "epochs = range(1, len(mean_pe_values) + 1)\n",
    "\n",
    "plt.plot(epochs, mean_pe_values, marker='o', linestyle='-', color='b', label='mean_PE')\n",
    "plt.fill_between(epochs, mean_pe_values - std_pe_values, mean_pe_values + std_pe_values, color='blue', alpha=0.3, label='std_dev_PE')\n",
    "\n",
    "plt.title('2mev: PE vs. Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
